{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0dcf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw conversation:\n",
      "Buyer: Hi, I'm interested in the apartment you listed.\n",
      "Seller: Of course, do you have a budget in mind?\n",
      "Buyer: Does it have parking?\n",
      "Seller: Yes, it comes with one covered parking.\n",
      "Buyer: What’s the price range?\n",
      "Seller: It’s a 10-minute walk to the metro station.\n",
      "Buyer: That sounds interesting, I’ll discuss with my family.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "base_path = r\"c:\\Users\\kau75421\\AI startup\\Datacollection\\split_conversations\"\n",
    "file_name = \"conversation_2031.txt\"\n",
    "file_path = os.path.join(base_path, file_name)\n",
    "\n",
    "# Read the file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    conversation = f.read()\n",
    "\n",
    "\n",
    "\n",
    "# Display the raw conversation\n",
    "print(\"Raw conversation:\")\n",
    "print(conversation)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35115c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Engagement Analytics:\n",
      "------------------------------\n",
      "Total Messages: 7\n",
      "Buyer Messages: 4\n",
      "Seller Messages: 3\n",
      "Seller Response Rate: 75.00%\n",
      "Direct Seller Responses: 3\n",
      "Average Message Length: 45.4 characters\n",
      "Questions Asked: 3\n"
     ]
    }
   ],
   "source": [
    "# Split conversation into messages\n",
    "messages = conversation.strip().split('\\n')\n",
    "\n",
    "# Calculate engagement metrics\n",
    "engagement_metrics = {\n",
    "    'total_messages': len(messages),\n",
    "    'buyer_messages': len([msg for msg in messages if msg.startswith('Buyer:')]),\n",
    "    'seller_messages': len([msg for msg in messages if msg.startswith('Seller:')]),\n",
    "    'response_rate': 0,\n",
    "    'avg_message_length': sum(len(msg) for msg in messages) / len(messages),\n",
    "    'questions_asked': len([msg for msg in messages if '?' in msg]),\n",
    "}\n",
    "\n",
    "# Calculate seller's response rate to buyer messages\n",
    "buyer_messages_count = engagement_metrics['buyer_messages']\n",
    "seller_responses = 0\n",
    "previous_was_buyer = False\n",
    "\n",
    "for message in messages:\n",
    "    if message.startswith('Buyer:'):\n",
    "        previous_was_buyer = True\n",
    "    elif message.startswith('Seller:') and previous_was_buyer:\n",
    "        seller_responses += 1\n",
    "        previous_was_buyer = False\n",
    "    else:\n",
    "        previous_was_buyer = False\n",
    "\n",
    "# Calculate response rate (seller responses / buyer messages that could have received responses)\n",
    "if buyer_messages_count > 0:\n",
    "    engagement_metrics['response_rate'] = seller_responses / buyer_messages_count\n",
    "\n",
    "# Print analytics\n",
    "print(\"Conversation Engagement Analytics:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Total Messages: {engagement_metrics['total_messages']}\")\n",
    "print(f\"Buyer Messages: {engagement_metrics['buyer_messages']}\")\n",
    "print(f\"Seller Messages: {engagement_metrics['seller_messages']}\")\n",
    "print(f\"Seller Response Rate: {engagement_metrics['response_rate']:.2%}\")\n",
    "print(f\"Direct Seller Responses: {seller_responses}\")\n",
    "print(f\"Average Message Length: {engagement_metrics['avg_message_length']:.1f} characters\")\n",
    "print(f\"Questions Asked: {engagement_metrics['questions_asked']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62ae6732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Word Count Analytics:\n",
      "------------------------------\n",
      "Buyer Average Words per Message: 6.0 words\n",
      "Seller Average Words per Message: 8.0 words\n",
      "Overall Average Words per Message: 6.9 words\n",
      "\n",
      "Detailed Word Counts:\n",
      "------------------------------\n",
      "\n",
      "Buyer Messages:\n",
      "Words: 8 - Message: Hi, I'm interested in the apartment you listed.\n",
      "Words: 4 - Message: Does it have parking?\n",
      "Words: 4 - Message: What’s the price range?\n",
      "Words: 8 - Message: That sounds interesting, I’ll discuss with my family.\n",
      "\n",
      "Seller Messages:\n",
      "Words: 9 - Message: Of course, do you have a budget in mind?\n",
      "Words: 7 - Message: Yes, it comes with one covered parking.\n",
      "Words: 8 - Message: It’s a 10-minute walk to the metro station.\n"
     ]
    }
   ],
   "source": [
    "# Split conversation into messages\n",
    "messages = conversation.strip().split('\\n')\n",
    "\n",
    "# Separate buyer and seller messages\n",
    "buyer_messages = [msg.replace('Buyer: ', '') for msg in messages if msg.startswith('Buyer:')]\n",
    "seller_messages = [msg.replace('Seller: ', '') for msg in messages if msg.startswith('Seller:')]\n",
    "\n",
    "# Calculate word lengths\n",
    "message_word_metrics = {\n",
    "    'buyer_avg_words': sum(len(msg.split()) for msg in buyer_messages) / len(buyer_messages) if buyer_messages else 0,\n",
    "    'seller_avg_words': sum(len(msg.split()) for msg in seller_messages) / len(seller_messages) if seller_messages else 0,\n",
    "    'overall_avg_words': sum(len(msg.split(': ')[1].split()) for msg in messages) / len(messages)\n",
    "}\n",
    "\n",
    "# Print analytics\n",
    "print(\"Message Word Count Analytics:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Buyer Average Words per Message: {message_word_metrics['buyer_avg_words']:.1f} words\")\n",
    "print(f\"Seller Average Words per Message: {message_word_metrics['seller_avg_words']:.1f} words\")\n",
    "print(f\"Overall Average Words per Message: {message_word_metrics['overall_avg_words']:.1f} words\")\n",
    "\n",
    "# Detailed word counts\n",
    "print(\"\\nDetailed Word Counts:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"\\nBuyer Messages:\")\n",
    "for msg in buyer_messages:\n",
    "    words = msg.split()\n",
    "    print(f\"Words: {len(words)} - Message: {msg}\")\n",
    "\n",
    "print(\"\\nSeller Messages:\")\n",
    "for msg in seller_messages:\n",
    "    words = msg.split()\n",
    "    print(f\"Words: {len(words)} - Message: {msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a00a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA preprocesing\n",
    "# Lower casing \n",
    "# removing stopwords \n",
    "# lemmatization\n",
    "# tokenization\n",
    "# removing special characters and punctuation\n",
    "# seprate buyer and seller messages into different lists\n",
    "# save the preprocessed data into a csv file with columns 'role' and 'message'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea230b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buyer: Hi, I'm interested in the apartment you listed.\n",
      "Seller: Of course, do you have a budget in mind?\n",
      "Buyer: Does it have parking?\n",
      "Seller: Yes, it comes with one covered parking.\n",
      "Buyer: What’s the price range?\n",
      "Seller: It’s a 10-minute walk to the metro station.\n",
      "Buyer: That sounds interesting, I’ll discuss with my family.\n"
     ]
    }
   ],
   "source": [
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b0328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Buyer:', \" Hi, I'm interested in the apartment you listed.\\n\", 'Seller:', ' Of course, do you have a budget in mind?\\n', 'Buyer:', ' Does it have parking?\\n', 'Seller:', ' Yes, it comes with one covered parking.\\n', 'Buyer:', ' What’s the price range?\\n', 'Seller:', ' It’s a 10-minute walk to the metro station.\\n', 'Buyer:', ' That sounds interesting, I’ll discuss with my family.']\n",
      "Buyer tokens: ['interested', 'listed', 'price', 'parking', 'family', 'range', 'apartment', 'interesting', 'does', 'discuss', 'hi', 'sounds', 'll']\n",
      "Seller tokens: ['course', 'covered', 'yes', 'parking', 'minute', 'station', 'budget', 'metro', 'walk', '10', 'mind', 'comes']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "\n",
    "# Stopwords\n",
    "stop_words = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "def separate_buyer_seller_from_string(conversation: str, deduplicate: bool = False):\n",
    "    \"\"\"\n",
    "    Process conversation string into Buyer and Seller tokens (stopwords removed).\n",
    "    \n",
    "    Args:\n",
    "        conversation: str with lines like 'Buyer: ... Seller: ...'\n",
    "        deduplicate: if True, removes duplicate words\n",
    "    \n",
    "    Returns:\n",
    "        buyer_tokens, seller_tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    def clean_text(text: str):\n",
    "        tokens = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "        return [w for w in tokens if w not in stop_words and len(w) > 1]\n",
    "    \n",
    "    buyer_list, seller_list = [], []\n",
    "    \n",
    "    # Split conversation by role markers\n",
    "    parts = re.split(r\"(Buyer:|Seller:)\", conversation)\n",
    "    print(parts)\n",
    "    \n",
    "    # parts will look like [\"\", \"Buyer:\", \"Hi I'm ...\", \"Seller:\", \"Of course...\", ...]\n",
    "    for i in range(1, len(parts), 2):\n",
    "        role = parts[i].replace(\":\", \"\").strip().lower()\n",
    "        text = parts[i+1].strip()\n",
    "        cleaned = clean_text(text)\n",
    "        \n",
    "        if role == \"buyer\":\n",
    "            buyer_list.extend(cleaned)\n",
    "        elif role == \"seller\":\n",
    "            seller_list.extend(cleaned)\n",
    "    \n",
    "    if deduplicate:\n",
    "        buyer_list = list(set(buyer_list))\n",
    "        seller_list = list(set(seller_list))\n",
    "    \n",
    "    return buyer_list, seller_list\n",
    "\n",
    "\n",
    "# ---------------- Example Usage ----------------\n",
    "buyer_tokens, seller_tokens = separate_buyer_seller_from_string(conversation, deduplicate=True)\n",
    "\n",
    "print(\"Buyer tokens:\", buyer_tokens)\n",
    "print(\"Seller tokens:\", seller_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c52f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Nouns/Noun-Phrases used by Buyer:\n",
      "hi: 1\n",
      "the apartment: 1\n",
      "the price range: 1\n",
      "ll discuss: 1\n",
      "family: 1\n",
      "\n",
      "Buyer Tone:\n",
      "tone: neutral\n",
      "score: 0.0\n"
     ]
    }
   ],
   "source": [
    "# ---- Buyer-only Noun Phrase Extractor ----\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "class BuyerNounExtractor:\n",
    "    \"\"\"\n",
    "    Extracts ONLY nouns and noun phrases (multi-word like 'credit card') from Buyer messages.\n",
    "    Ignores Seller completely.\n",
    "    Excludes filler words: 'is', 'am', 'are'.\n",
    "    Uses spaCy noun_chunks if available; falls back to NLTK chunking if not.\n",
    "    Also returns a light tone summary for Buyer.\n",
    "    \"\"\"\n",
    "    EXCLUDE_TOKENS = {\"is\", \"am\", \"are\"}\n",
    "\n",
    "    def __init__(self, conversation_text: str):\n",
    "        self.raw = conversation_text\n",
    "        self.buyer_text = self._extract_buyer_text(conversation_text)\n",
    "        self._nlp = None\n",
    "        self._use_spacy = False\n",
    "\n",
    "        # basic tone words\n",
    "        self._positive = {\"good\", \"great\", \"thanks\", \"thank\", \"excellent\", \"happy\", \"pleased\", \"fine\", \"perfect\"}\n",
    "        self._negative = {\"bad\", \"problem\", \"issue\", \"angry\", \"disappointed\", \"no\", \"not\", \"worst\", \"never\"}\n",
    "\n",
    "    # ----------------- Message Parsing -----------------\n",
    "    def _extract_buyer_text(self, text):\n",
    "        \"\"\"Extract all Buyer messages (lines starting with 'Buyer:') and join them.\"\"\"\n",
    "        lines = text.splitlines()\n",
    "        buyer_msgs = []\n",
    "        for ln in lines:\n",
    "            if ln.strip().startswith(\"Buyer:\"):\n",
    "                msg = ln.split(\"Buyer:\", 1)[1].strip()\n",
    "                if msg:\n",
    "                    buyer_msgs.append(msg)\n",
    "        return \"\\n\".join(buyer_msgs).strip()\n",
    "\n",
    "    # ----------------- NLP Setup -----------------\n",
    "    def _init_spacy(self):\n",
    "        \"\"\"Try to load spaCy model; fallback to NLTK if not available.\"\"\"\n",
    "        if self._nlp is not None:\n",
    "            return\n",
    "        try:\n",
    "            import spacy\n",
    "            try:\n",
    "                self._nlp = spacy.load(\"en_core_web_sm\")\n",
    "            except Exception:\n",
    "                from spacy.cli import download\n",
    "                download(\"en_core_web_sm\")\n",
    "                self._nlp = spacy.load(\"en_core_web_sm\")\n",
    "            self._use_spacy = True\n",
    "        except Exception:\n",
    "            self._use_spacy = False\n",
    "            self._nlp = None\n",
    "\n",
    "    # ----------------- Noun Phrase Extraction -----------------\n",
    "    def _extract_with_spacy(self, text):\n",
    "        \"\"\"Extract noun phrases using spaCy noun_chunks and single-word NOUN/PROPN tokens.\"\"\"\n",
    "        doc = self._nlp(text)\n",
    "        phrases = []\n",
    "\n",
    "        # multi-word noun chunks\n",
    "        for chunk in doc.noun_chunks:\n",
    "            tokens = [tok.lemma_.lower() for tok in chunk if tok.lemma_.lower() not in self.EXCLUDE_TOKENS]\n",
    "            phrase = \" \".join(tokens).strip()\n",
    "            if phrase:\n",
    "                phrases.append(phrase)\n",
    "\n",
    "        # single-word nouns not already captured\n",
    "        for tok in doc:\n",
    "            if tok.pos_ in {\"NOUN\", \"PROPN\"}:\n",
    "                lemma = tok.lemma_.lower().strip()\n",
    "                if lemma not in self.EXCLUDE_TOKENS:\n",
    "                    phrases.append(lemma)\n",
    "        return phrases\n",
    "\n",
    "    def _extract_with_nltk(self, text):\n",
    "        \"\"\"Fallback noun phrase extraction using NLTK.\"\"\"\n",
    "        try:\n",
    "            import nltk\n",
    "            nltk.download(\"punkt\", quiet=True)\n",
    "            nltk.download(\"averaged_perceptron_tagger\", quiet=True)\n",
    "            from nltk import word_tokenize, pos_tag, RegexpParser\n",
    "\n",
    "            tokens = word_tokenize(text)\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            grammar = r\"NP: {<DT>?<JJ>*<NN.*>+}\"\n",
    "            chunk_parser = RegexpParser(grammar)\n",
    "            tree = chunk_parser.parse(pos_tags)\n",
    "\n",
    "            phrases = []\n",
    "            for subtree in tree:\n",
    "                if hasattr(subtree, \"label\") and subtree.label() == \"NP\":\n",
    "                    phrase = \" \".join(w.lower() for w, _ in subtree.leaves())\n",
    "                    if phrase not in self.EXCLUDE_TOKENS:\n",
    "                        phrases.append(phrase)\n",
    "            return phrases\n",
    "        except Exception:\n",
    "            # fallback to simple word extraction\n",
    "            return re.findall(r\"\\b[a-zA-Z]{2,}\\b\", text.lower())\n",
    "\n",
    "    # ----------------- Main Logic -----------------\n",
    "    def extract_buyer_nouns(self, top_k=30):\n",
    "        \"\"\"Return top noun phrases used by Buyer.\"\"\"\n",
    "        if not self.buyer_text:\n",
    "            return Counter()\n",
    "        self._init_spacy()\n",
    "\n",
    "        if self._use_spacy:\n",
    "            phrases = self._extract_with_spacy(self.buyer_text)\n",
    "        else:\n",
    "            phrases = self._extract_with_nltk(self.buyer_text)\n",
    "\n",
    "        phrases = [p for p in phrases if p and p not in self.EXCLUDE_TOKENS]\n",
    "        counter = Counter(phrases)\n",
    "        return counter.most_common(top_k)\n",
    "\n",
    "    # ----------------- Tone Analysis -----------------\n",
    "    def analyze_tone(self):\n",
    "        \"\"\"Basic tone based on positive/negative words.\"\"\"\n",
    "        txt = self.buyer_text.lower()\n",
    "        words = re.findall(r\"\\b[a-zA-Z]+\\b\", txt)\n",
    "        total = max(1, len(words))\n",
    "        pos = sum(1 for w in words if w in self._positive)\n",
    "        neg = sum(1 for w in words if w in self._negative)\n",
    "        score = (pos - neg) / total\n",
    "        tone = \"positive\" if score > 0.03 else \"negative\" if score < -0.03 else \"neutral\"\n",
    "        return {\"tone\": tone, \"score\": round(score, 3)}\n",
    "\n",
    "    def run(self, top_k=30):\n",
    "        \"\"\"Run full analysis: buyer-only noun extraction + tone.\"\"\"\n",
    "        nouns = self.extract_buyer_nouns(top_k=top_k)\n",
    "        tone = self.analyze_tone()\n",
    "        return {\"buyer_nouns\": nouns, \"tone\": tone}\n",
    "\n",
    "# ---------------- Example Usage ----------------\n",
    "analyzer = BuyerNounExtractor(conversation)\n",
    "result = analyzer.run(top_k=40)\n",
    "\n",
    "print(\"Top Nouns/Noun-Phrases used by Buyer:\")\n",
    "for phrase, count in result[\"buyer_nouns\"]:\n",
    "    print(f\"{phrase}: {count}\")\n",
    "\n",
    "print(\"\\nBuyer Tone:\")\n",
    "for k, v in result[\"tone\"].items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ---------------- Complexity ----------------\n",
    "# Time: O(N) for tokenization/POS tagging, O(M log M) for sorting noun frequencies\n",
    "# Space: O(N) for token storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4505181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Seller Performance Summary ===\n",
      "Total messages: 7 | Buyer: 4 | Seller: 3\n",
      "Average seller words per message: 8.7\n",
      "\n",
      "Seller direct responses following buyer messages: 3 / 4 (rate: 75.0%)\n",
      "Buyer questions: 2 | Answered (estimated): 2 | Answer rate: 100.0%\n",
      "\n",
      "Politeness score (fraction of seller messages with polite markers): 0.0\n",
      "Helpfulness score (fraction offering action/resolution): 0.0\n",
      "\n",
      "Negative/limiting replies: 0 | All-caps tokens (possible raised tone): 0\n",
      "\n",
      "Overall assessment: Good (score: 0.6)\n",
      "\n",
      "Suggestions to improve seller performance:\n",
      " - Increase responsiveness: try to reply directly after buyer messages more often.\n",
      " - Use more polite phrases (please, thank you) to improve rapport.\n",
      " - Offer clear actions (send link, arrange shipment, provide ETA) rather than short/deflecting replies.\n"
     ]
    }
   ],
   "source": [
    "# ---- Seller performance analysis (text-only, Buyer/Seller format) ----\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "class SellerPerformanceAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze seller performance from a Buyer/Seller style conversation (text only).\n",
    "    Provides:\n",
    "      - counts & averages\n",
    "      - seller response rate (seller replies following buyer messages)\n",
    "      - estimated answer rate to buyer questions\n",
    "      - politeness/helpfulness/resolution heuristics\n",
    "      - suggested improvements\n",
    "    Note: Without timestamps we cannot compute true response times; we use message order heuristics.\n",
    "    \"\"\"\n",
    "\n",
    "    # small lexicons for heuristics\n",
    "    POLITE_MARKERS = {\"please\", \"thank you\", \"thanks\", \"regards\", \"sorry\", \"appreciate\", \"kindly\"}\n",
    "    NEGATIVE_MARKERS = {\"can't\", \"cannot\", \"won't\", \"unable\", \"not available\", \"no stock\", \"out of stock\", \"delay\"}\n",
    "    RESOLUTION_MARKERS = {\"shipped\", \"sent\", \"delivered\", \"resolved\", \"fixed\", \"done\", \"completed\", \"refund\", \"replaced\", \"invoice\", \"paid\", \"booked\"}\n",
    "    ACTION_OFFER_MARKERS = {\"i can\", \"i will\", \"i'll\", \"we can\", \"we will\", \"we'll\", \"send\", \"share\", \"provide\", \"arrange\", \"schedule\", \"call you\", \"call\"}\n",
    "\n",
    "    def __init__(self, conversation_text: str):\n",
    "        self.raw = conversation_text\n",
    "        self.messages = self._split_messages(conversation_text)  # list[(speaker, text)]\n",
    "        self.seller_messages = [t for s, t in self.messages if s == \"Seller\"]\n",
    "        self.buyer_messages = [t for s, t in self.messages if s == \"Buyer\"]\n",
    "\n",
    "    # ------------------ parsing ------------------\n",
    "    def _split_messages(self, text):\n",
    "        \"\"\"\n",
    "        Split conversation into (speaker, text) blocks using exact 'Buyer:' and 'Seller:' prefixes.\n",
    "        Preserves message order.\n",
    "        \"\"\"\n",
    "        lines = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").split(\"\\n\")\n",
    "        messages = []\n",
    "        current_speaker = None\n",
    "        current_lines = []\n",
    "        prefixes = (\"Buyer:\", \"Seller:\")\n",
    "\n",
    "        for ln in lines:\n",
    "            stripped = ln.strip()\n",
    "            if not stripped:\n",
    "                if current_speaker is not None:\n",
    "                    current_lines.append(\"\")\n",
    "                continue\n",
    "\n",
    "            matched = False\n",
    "            for p in prefixes:\n",
    "                if stripped.startswith(p):\n",
    "                    if current_speaker is not None:\n",
    "                        messages.append((current_speaker, \"\\n\".join(current_lines).strip()))\n",
    "                    current_speaker = p[:-1]  # 'Buyer' or 'Seller'\n",
    "                    remainder = stripped[len(p):].strip()\n",
    "                    current_lines = [remainder] if remainder else []\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                if current_speaker is None:\n",
    "                    # unknown speaker until first prefix - attach as Unknown (ignored later)\n",
    "                    current_speaker = \"Unknown\"\n",
    "                    current_lines = [stripped]\n",
    "                else:\n",
    "                    current_lines.append(stripped)\n",
    "\n",
    "        if current_speaker is not None:\n",
    "            messages.append((current_speaker, \"\\n\".join(current_lines).strip()))\n",
    "        return messages\n",
    "\n",
    "    # ------------------ utilities ------------------\n",
    "    @staticmethod\n",
    "    def _word_count(text):\n",
    "        return len(re.findall(r\"\\w+\", text))\n",
    "\n",
    "    @staticmethod\n",
    "    def _contains_any(text, keywords):\n",
    "        t = text.lower()\n",
    "        return any(k in t for k in keywords)\n",
    "\n",
    "    # ------------------ metrics ------------------\n",
    "    def basic_activity_metrics(self):\n",
    "        total_msgs = len(self.messages)\n",
    "        seller_count = len(self.seller_messages)\n",
    "        buyer_count = len(self.buyer_messages)\n",
    "        avg_seller_len = (sum(self._word_count(m) for m in self.seller_messages) / seller_count) if seller_count else 0\n",
    "        avg_buyer_len = (sum(self._word_count(m) for m in self.buyer_messages) / buyer_count) if buyer_count else 0\n",
    "\n",
    "        return {\n",
    "            \"total_messages\": total_msgs,\n",
    "            \"seller_messages\": seller_count,\n",
    "            \"buyer_messages\": buyer_count,\n",
    "            \"avg_seller_words\": round(avg_seller_len, 1),\n",
    "            \"avg_buyer_words\": round(avg_buyer_len, 1)\n",
    "        }\n",
    "\n",
    "    def seller_response_rate(self):\n",
    "        \"\"\"\n",
    "        Response rate heuristic:\n",
    "        Count instances where a Seller message immediately follows a Buyer message.\n",
    "        response_rate = seller_responses_after_buyer / total_buyer_messages_that_could_receive_response\n",
    "        \"\"\"\n",
    "        seller_responses = 0\n",
    "        buyer_msgs_that_could_get_response = 0\n",
    "        prev_is_buyer = False\n",
    "\n",
    "        for spk, txt in self.messages:\n",
    "            if spk == \"Buyer\":\n",
    "                prev_is_buyer = True\n",
    "                buyer_msgs_that_could_get_response += 1\n",
    "            elif spk == \"Seller\":\n",
    "                if prev_is_buyer:\n",
    "                    seller_responses += 1\n",
    "                prev_is_buyer = False\n",
    "            else:\n",
    "                prev_is_buyer = False\n",
    "\n",
    "        rate = (seller_responses / buyer_msgs_that_could_get_response) if buyer_msgs_that_could_get_response else 0.0\n",
    "        return {\"seller_direct_responses\": seller_responses,\n",
    "                \"buyer_msgs_that_could_get_response\": buyer_msgs_that_could_get_response,\n",
    "                \"response_rate\": round(rate, 3)}\n",
    "\n",
    "    def answer_rate_to_questions(self):\n",
    "        \"\"\"\n",
    "        Estimate how many buyer questions were answered.\n",
    "        - Identify buyer messages that contain a question mark (or 'how', 'what', 'when', etc.)\n",
    "        - For each such buyer question, inspect the next Seller message (if any) and see if it\n",
    "          contains an apparent answer (resolution markers, action offers, or absence of clarifying question).\n",
    "        This is heuristic: may be conservative.\n",
    "        \"\"\"\n",
    "        q_markers = {\"how\", \"what\", \"when\", \"where\", \"why\", \"which\", \"who\", \"can\", \"could\", \"would\"}\n",
    "        buyer_questions = []\n",
    "        # collect indices of buyer question messages\n",
    "        for idx, (spk, txt) in enumerate(self.messages):\n",
    "            if spk == \"Buyer\":\n",
    "                low = txt.lower()\n",
    "                if \"?\" in txt or any(re.search(r\"\\b\" + qm + r\"\\b\", low) for qm in q_markers):\n",
    "                    buyer_questions.append(idx)\n",
    "\n",
    "        answered = 0\n",
    "        unresolved = 0\n",
    "        for idx in buyer_questions:\n",
    "            # look for next seller message after this buyer question\n",
    "            next_seller_text = None\n",
    "            for j in range(idx + 1, len(self.messages)):\n",
    "                if self.messages[j][0] == \"Seller\":\n",
    "                    next_seller_text = self.messages[j][1]\n",
    "                    break\n",
    "                elif self.messages[j][0] == \"Buyer\":\n",
    "                    # another buyer message before any seller reply -> likely unanswered\n",
    "                    break\n",
    "            if next_seller_text:\n",
    "                low = next_seller_text.lower()\n",
    "                # heuristics indicating answer/help:\n",
    "                if (self._contains_any(low, self.RESOLUTION_MARKERS)\n",
    "                        or self._contains_any(low, self.ACTION_OFFER_MARKERS)\n",
    "                        or not re.search(r\"\\b(can you|could you|please provide|pls provide|please let me)\\b\", low)):\n",
    "                    answered += 1\n",
    "                else:\n",
    "                    unresolved += 1\n",
    "            else:\n",
    "                unresolved += 1\n",
    "\n",
    "        total_q = len(buyer_questions)\n",
    "        answer_rate = (answered / total_q) if total_q else None\n",
    "        return {\"buyer_questions\": total_q, \"answered\": answered, \"unanswered\": unresolved, \"answer_rate\": round(answer_rate, 3) if answer_rate is not None else None}\n",
    "\n",
    "    def politeness_and_helpfulness(self):\n",
    "        \"\"\"\n",
    "        Heuristic scoring for politeness and helpfulness:\n",
    "          - politeness_score: fraction of seller messages containing polite markers\n",
    "          - helpfulness_score: fraction containing action offers or resolution markers\n",
    "        \"\"\"\n",
    "        seller_count = len(self.seller_messages)\n",
    "        if seller_count == 0:\n",
    "            return {\"politeness_score\": 0.0, \"helpfulness_score\": 0.0, \"examples_polite\": [], \"examples_helpful\": []}\n",
    "\n",
    "        polite_hits = 0\n",
    "        helpful_hits = 0\n",
    "        polite_examples = []\n",
    "        helpful_examples = []\n",
    "\n",
    "        for msg in self.seller_messages:\n",
    "            low = msg.lower()\n",
    "            is_polite = self._contains_any(low, self.POLITE_MARKERS)\n",
    "            is_helpful = (self._contains_any(low, self.ACTION_OFFER_MARKERS) or self._contains_any(low, self.RESOLUTION_MARKERS))\n",
    "            if is_polite:\n",
    "                polite_hits += 1\n",
    "                if len(polite_examples) < 3:\n",
    "                    polite_examples.append(msg[:200])\n",
    "            if is_helpful:\n",
    "                helpful_hits += 1\n",
    "                if len(helpful_examples) < 3:\n",
    "                    helpful_examples.append(msg[:200])\n",
    "\n",
    "        return {\n",
    "            \"politeness_score\": round(polite_hits / seller_count, 3),\n",
    "            \"helpfulness_score\": round(helpful_hits / seller_count, 3),\n",
    "            \"examples_polite\": polite_examples,\n",
    "            \"examples_helpful\": helpful_examples\n",
    "        }\n",
    "\n",
    "    def escalation_and_negative_signals(self):\n",
    "        \"\"\"\n",
    "        Look for negative / escalation signals in seller replies:\n",
    "          - use of negative markers, refusal language, many unanswered buyer questions, or repeated 'not available' phrases.\n",
    "        \"\"\"\n",
    "        neg_count = sum(1 for m in self.seller_messages if self._contains_any(m, self.NEGATIVE_MARKERS))\n",
    "        caps_shouting = sum(1 for m in self.seller_messages if re.search(r\"\\b[A-Z]{3,}\\b\", m))\n",
    "        return {\"neg_count\": neg_count, \"caps_shouting\": caps_shouting}\n",
    "\n",
    "    # ------------------ overall assessment ------------------\n",
    "    def performance_summary(self):\n",
    "        basic = self.basic_activity_metrics()\n",
    "        resp = self.seller_response_rate()\n",
    "        answer = self.answer_rate_to_questions()\n",
    "        tone_help = self.politeness_and_helpfulness()\n",
    "        neg = self.escalation_and_negative_signals()\n",
    "\n",
    "        # simple rule-based judgment\n",
    "        score_components = []\n",
    "        # response rate contributes (weight 0.4)\n",
    "        score_components.append((resp[\"response_rate\"] or 0) * 0.4)\n",
    "        # answer rate contributes (0.3) - if None, assume 0.15 neutral\n",
    "        answer_rate_val = answer[\"answer_rate\"] if answer[\"answer_rate\"] is not None else 0.15\n",
    "        score_components.append(answer_rate_val * 0.3)\n",
    "        # helpfulness (0.2)\n",
    "        score_components.append(tone_help[\"helpfulness_score\"] * 0.2)\n",
    "        # politeness (0.1)\n",
    "        score_components.append(tone_help[\"politeness_score\"] * 0.1)\n",
    "\n",
    "        overall_score = sum(score_components)  # range roughly 0..1\n",
    "        overall_label = \"Excellent\" if overall_score >= 0.75 else \"Good\" if overall_score >= 0.5 else \"Needs Improvement\"\n",
    "\n",
    "        suggestions = []\n",
    "        # heuristics for improvement suggestions\n",
    "        if resp[\"response_rate\"] < 0.8:\n",
    "            suggestions.append(\"Increase responsiveness: try to reply directly after buyer messages more often.\")\n",
    "        if answer[\"answer_rate\"] is None or answer[\"answer_rate\"] < 0.7:\n",
    "            suggestions.append(\"Improve question answering: when buyer asks, provide direct answers or clear next steps.\")\n",
    "        if tone_help[\"politeness_score\"] < 0.6:\n",
    "            suggestions.append(\"Use more polite phrases (please, thank you) to improve rapport.\")\n",
    "        if tone_help[\"helpfulness_score\"] < 0.5:\n",
    "            suggestions.append(\"Offer clear actions (send link, arrange shipment, provide ETA) rather than short/deflecting replies.\")\n",
    "        if neg[\"neg_count\"] > 0:\n",
    "            suggestions.append(\"Avoid negative phrasing when possible; provide alternatives instead of blunt 'not available' answers.\")\n",
    "        if neg[\"caps_shouting\"] > 0:\n",
    "            suggestions.append(\"Avoid all-caps words; they may be perceived as shouting.\")\n",
    "\n",
    "        summary = {\n",
    "            \"basic_metrics\": basic,\n",
    "            \"response_metrics\": resp,\n",
    "            \"question_answering\": answer,\n",
    "            \"politeness_helpfulness\": tone_help,\n",
    "            \"neg_signals\": neg,\n",
    "            \"overall_score\": round(overall_score, 3),\n",
    "            \"overall_label\": overall_label,\n",
    "            \"suggestions\": suggestions\n",
    "        }\n",
    "        return summary\n",
    "\n",
    "    # ------------------ run ------------------\n",
    "    def run(self):\n",
    "        return self.performance_summary()\n",
    "\n",
    "# ------------------ Example usage ------------------\n",
    "analyzer = SellerPerformanceAnalyzer(conversation)\n",
    "report = analyzer.run()\n",
    "\n",
    "# Nicely print a human-friendly summary\n",
    "print(\"=== Seller Performance Summary ===\")\n",
    "bm = report[\"basic_metrics\"]\n",
    "print(f\"Total messages: {bm['total_messages']} | Buyer: {bm['buyer_messages']} | Seller: {bm['seller_messages']}\")\n",
    "print(f\"Average seller words per message: {bm['avg_seller_words']}\")\n",
    "print()\n",
    "rm = report[\"response_metrics\"]\n",
    "print(f\"Seller direct responses following buyer messages: {rm['seller_direct_responses']} / {rm['buyer_msgs_that_could_get_response']} (rate: {rm['response_rate']*100:.1f}%)\")\n",
    "ans = report[\"question_answering\"]\n",
    "if ans[\"answer_rate\"] is not None:\n",
    "    print(f\"Buyer questions: {ans['buyer_questions']} | Answered (estimated): {ans['answered']} | Answer rate: {ans['answer_rate']*100:.1f}%\")\n",
    "else:\n",
    "    print(f\"Buyer questions: {ans['buyer_questions']} | Answered (estimated): {ans['answered']}\")\n",
    "print()\n",
    "ph = report[\"politeness_helpfulness\"]\n",
    "print(f\"Politeness score (fraction of seller messages with polite markers): {ph['politeness_score']}\")\n",
    "print(f\"Helpfulness score (fraction offering action/resolution): {ph['helpfulness_score']}\")\n",
    "if ph[\"examples_polite\"]:\n",
    "    print(\"\\nExample polite seller messages:\")\n",
    "    for ex in ph[\"examples_polite\"]:\n",
    "        print(\" -\", ex)\n",
    "if ph[\"examples_helpful\"]:\n",
    "    print(\"\\nExample helpful seller messages:\")\n",
    "    for ex in ph[\"examples_helpful\"]:\n",
    "        print(\" -\", ex)\n",
    "print()\n",
    "ns = report[\"neg_signals\"]\n",
    "print(f\"Negative/limiting replies: {ns['neg_count']} | All-caps tokens (possible raised tone): {ns['caps_shouting']}\")\n",
    "print()\n",
    "print(\"Overall assessment:\", report[\"overall_label\"], f\"(score: {report['overall_score']})\")\n",
    "print(\"\\nSuggestions to improve seller performance:\")\n",
    "for s in report[\"suggestions\"]:\n",
    "    print(\" -\", s)\n",
    "\n",
    "# ------------------ Complexity notes ------------------\n",
    "# Time: O(N) to scan messages and simple pattern checks where N = number of messages / tokens\n",
    "# Space: O(N) for storing split messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb5b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e3de055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Conversation Categorization ===\n",
      "Category: highly_important\n",
      "Score: 3.6\n",
      "Recommendation: Immediate follow-up: assign high priority sales outreach; send proposal/arrange meeting.\n",
      "Signals: {'interest_phrases': 2, 'questions': 2, 'followup_requests': 0, 'negative_phrases': 0, 'short_hangups': 0}\n",
      "Reason: ['Buyer requested follow-up or showed strong multi-signal interest.']\n",
      "\n",
      "Evidence snippets (sample):\n",
      "- [interest] Hi, I'm interested in the apartment you listed.\n",
      "- [question] Does it have parking?\n",
      "- [interest] What’s the price range?\n",
      "- [question] What’s the price range?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class ConversationCategorizer:\n",
    "    \"\"\"\n",
    "    Classify a Buyer/Seller conversation into:\n",
    "      - 'black_listed' (not interested / cut call / refused)\n",
    "      - 'good_call' (showed interest / worth follow-up)\n",
    "      - 'highly_important' (strong interest / requested more info or next steps)\n",
    "    Heuristics are rule-based and operate on Buyer messages and call-related lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # Signals / phrases\n",
    "    CALL_INDICATORS = [\n",
    "        \"picked up\", \"picked the call\", \"call connected\", \"on call\", \"in a call\",\n",
    "        \"connected on call\", \"we called\", \"you called\", \"called you\", \"call me\",\n",
    "        \"hung up\", \"hang up\", \"cut the call\", \"cut the line\", \"disconnected\", \"call dropped\"\n",
    "    ]\n",
    "    NEGATIVE_MARKERS = [\n",
    "        \"not interested\", \"no interested\", \"no thanks\", \"no thank you\", \"nope\", \"not now\",\n",
    "        \"don't call\", \"dont call\", \"unsubscribe\", \"not looking\", \"no need\", \"no thank\",\n",
    "        \"no interest\", \"cancel\", \"stop calling\"\n",
    "    ]\n",
    "    SHORT_REFUSAL_PATTERNS = [\n",
    "        r\"^\\s*no\\s*\\.?$\", r\"^\\s*nah\\s*\\.?$\", r\"^\\s*not interested\\s*\\.?$\", r\"^\\s*no thanks\\s*\\.?$\",\n",
    "        r\"^\\s*bye\\s*\\.?$\", r\"^\\s*ok\\s*\\.?$\"\n",
    "    ]\n",
    "    INTEREST_MARKERS = [\n",
    "        \"interested\", \"tell me more\", \"send details\", \"send me\", \"send info\", \"send information\",\n",
    "        \"pricing\", \"price\", \"how much\", \"quote\", \"demo\", \"meeting\", \"schedule\", \"when can\", \"call me back\",\n",
    "        \"i want\", \"we want\", \"can i\", \"can we\", \"order\", \"buy\", \"purchase\", \"sign up\", \"subscribe\", \"trial\",\n",
    "        \"more info\", \"more information\", \"details\", \"contact me\", \"email me\", \"send proposal\", \"proposal\"\n",
    "    ]\n",
    "    FOLLOWUP_REQUESTS = [\n",
    "        \"send details\", \"send me\", \"email me\", \"call me\", \"schedule\", \"book\", \"meeting\", \"demo\", \"proposal\"\n",
    "    ]\n",
    "    QUESTION_WORDS = {\"how\", \"what\", \"when\", \"where\", \"why\", \"which\", \"who\", \"can\", \"could\", \"would\"}\n",
    "\n",
    "    def __init__(self, conversation_text: str):\n",
    "        self.raw = conversation_text\n",
    "        self.messages = self._split_messages(conversation_text)  # list of (speaker, text)\n",
    "        self.buyer_messages = [(i, t) for i, (s, t) in enumerate(self.messages) if s == \"Buyer\"]\n",
    "        # Precompute lower versions\n",
    "        self._buyer_lower = [(i, t, t.lower()) for i, t in self.buyer_messages]\n",
    "\n",
    "    def _split_messages(self, text):\n",
    "        \"\"\"Split into (speaker, text) using 'Buyer:' / 'Seller:' prefixes preserving order.\"\"\"\n",
    "        lines = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").split(\"\\n\")\n",
    "        messages = []\n",
    "        current_speaker = None\n",
    "        current_lines = []\n",
    "        prefixes = (\"Buyer:\", \"Seller:\")\n",
    "\n",
    "        for ln in lines:\n",
    "            stripped = ln.strip()\n",
    "            if not stripped:\n",
    "                if current_speaker is not None:\n",
    "                    current_lines.append(\"\")\n",
    "                continue\n",
    "            matched = False\n",
    "            for p in prefixes:\n",
    "                if stripped.startswith(p):\n",
    "                    if current_speaker is not None:\n",
    "                        messages.append((current_speaker, \"\\n\".join(current_lines).strip()))\n",
    "                    current_speaker = p[:-1]  # Buyer or Seller\n",
    "                    remainder = stripped[len(p):].strip()\n",
    "                    current_lines = [remainder] if remainder else []\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                if current_speaker is None:\n",
    "                    current_speaker = \"Unknown\"\n",
    "                    current_lines = [stripped]\n",
    "                else:\n",
    "                    current_lines.append(stripped)\n",
    "        if current_speaker is not None:\n",
    "            messages.append((current_speaker, \"\\n\".join(current_lines).strip()))\n",
    "        return messages\n",
    "\n",
    "    def _contains_any(self, text_lower, keywords):\n",
    "        \"\"\"Return True if any keyword appears in the lower-cased text.\"\"\"\n",
    "        return any(k in text_lower for k in keywords)\n",
    "\n",
    "    def _matches_short_refusal(self, text):\n",
    "        for pat in self.SHORT_REFUSAL_PATTERNS:\n",
    "            if re.search(pat, text.strip(), flags=re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def categorize(self):\n",
    "        \"\"\"\n",
    "        Main categorization logic. Returns dict:\n",
    "          { 'category': str, 'score': float, 'signals': {...}, 'recommendation': str, 'evidence': [...] }\n",
    "        \"\"\"\n",
    "        signals = defaultdict(int)\n",
    "        evidence = []\n",
    "\n",
    "        # Scan buyer messages for call events nearby and signals\n",
    "        for idx, text, low in self._buyer_lower:\n",
    "            # call indicator present in same buyer line\n",
    "            if self._contains_any(low, self.CALL_INDICATORS):\n",
    "                signals['call_mentions'] += 1\n",
    "                evidence.append((\"call_mention\", text))\n",
    "\n",
    "            # negative markers\n",
    "            if self._contains_any(low, self.NEGATIVE_MARKERS) or self._matches_short_refusal(text):\n",
    "                signals['negative_phrases'] += 1\n",
    "                evidence.append((\"negative\", text))\n",
    "\n",
    "            # interest markers\n",
    "            if self._contains_any(low, self.INTEREST_MARKERS):\n",
    "                signals['interest_phrases'] += 1\n",
    "                evidence.append((\"interest\", text))\n",
    "\n",
    "            # explicit follow-up requests (strong signal)\n",
    "            if self._contains_any(low, self.FOLLOWUP_REQUESTS):\n",
    "                signals['followup_requests'] += 1\n",
    "                evidence.append((\"followup\", text))\n",
    "\n",
    "            # questions\n",
    "            if (\"?\" in text) or any(re.search(r\"\\b\" + qw + r\"\\b\", low) for qw in self.QUESTION_WORDS):\n",
    "                signals['questions'] += 1\n",
    "                evidence.append((\"question\", text))\n",
    "\n",
    "            # very short buyer messages (possible cut / hung up)\n",
    "            word_count = len(re.findall(r\"\\b\\w+\\b\", text))\n",
    "            if word_count <= 3 and (self._matches_short_refusal(text) or self._contains_any(low, [\"hung up\", \"hang up\", \"cut\", \"bye\"])):\n",
    "                signals['short_hangups'] += 1\n",
    "                evidence.append((\"short_hangup\", text))\n",
    "            elif word_count <= 2 and low in {\"no\", \"nah\", \"nope\"}:\n",
    "                signals['short_hangups'] += 1\n",
    "                evidence.append((\"short_refusal\", text))\n",
    "\n",
    "        # Additional heuristic: check buyer message immediately after a call-indicator (which might be in seller message)\n",
    "        # Find indices where seller says 'picked up' or 'call connected' etc, then inspect following buyer message\n",
    "        for i, (spk, txt) in enumerate(self.messages):\n",
    "            if spk == \"Seller\" and self._contains_any(txt.lower(), self.CALL_INDICATORS):\n",
    "                # look at next buyer message (if exists)\n",
    "                for j in range(i+1, len(self.messages)):\n",
    "                    if self.messages[j][0] == \"Buyer\":\n",
    "                        btxt = self.messages[j][1]\n",
    "                        blow = btxt.lower()\n",
    "                        wc = len(re.findall(r\"\\b\\w+\\b\", btxt))\n",
    "                        if self._contains_any(blow, self.NEGATIVE_MARKERS) or self._matches_short_refusal(btxt) or wc <= 3:\n",
    "                            signals['short_hangups'] += 1\n",
    "                            evidence.append((\"post_call_short\", btxt))\n",
    "                        elif self._contains_any(blow, self.INTEREST_MARKERS) or self._contains_any(blow, self.FOLLOWUP_REQUESTS):\n",
    "                            signals['interest_phrases'] += 1\n",
    "                            evidence.append((\"post_call_interest\", btxt))\n",
    "                        break\n",
    "\n",
    "        # Compute a simple interest score\n",
    "        # positive contributions\n",
    "        score = 0.0\n",
    "        score += signals['interest_phrases'] * 1.0\n",
    "        score += signals['questions'] * 0.8\n",
    "        score += signals['followup_requests'] * 1.8\n",
    "        # negative contributions\n",
    "        score -= signals['negative_phrases'] * 1.5\n",
    "        score -= signals['short_hangups'] * 2.5\n",
    "\n",
    "        # Determine category by rules (ordered)\n",
    "        category = \"black_listed\"\n",
    "        reason = []\n",
    "        # Rule 1: strong negative / immediate hangup -> black listed\n",
    "        if signals['short_hangups'] > 0 and signals['negative_phrases'] >= 1:\n",
    "            category = \"black_listed\"\n",
    "            reason.append(\"Short hangup / direct negative phrase detected right after call.\")\n",
    "        elif signals['short_hangups'] >= 2 and signals['interest_phrases'] == 0:\n",
    "            category = \"black_listed\"\n",
    "            reason.append(\"Multiple short hangups / refusals; likely not interested.\")\n",
    "        # Rule 2: highly important if follow-up requested or many interest signals\n",
    "        elif signals['followup_requests'] > 0 or (signals['interest_phrases'] >= 2 and signals['questions'] >= 1):\n",
    "            category = \"highly_important\"\n",
    "            reason.append(\"Buyer requested follow-up or showed strong multi-signal interest.\")\n",
    "        # Rule 3: good call if at least some interest/questions and not dominated by negatives\n",
    "        elif score >= 1.0:\n",
    "            category = \"good_call\"\n",
    "            reason.append(\"Buyer showed interest or asked questions — worthy of follow-up.\")\n",
    "        else:\n",
    "            # fallback: if there are explicit negative phrases and no interest -> black_listed\n",
    "            if signals['negative_phrases'] > 0 and signals['interest_phrases'] == 0:\n",
    "                category = \"black_listed\"\n",
    "                reason.append(\"Negative phrase(s) found with no interest signals.\")\n",
    "            else:\n",
    "                # otherwise treat as good_call if any mild signals, else blacklisted\n",
    "                if signals['interest_phrases'] > 0 or signals['questions'] > 0:\n",
    "                    category = \"good_call\"\n",
    "                    reason.append(\"Mild interest found.\")\n",
    "                else:\n",
    "                    category = \"black_listed\"\n",
    "                    reason.append(\"No clear interest signals; treat as not interested.\")\n",
    "\n",
    "        # Recommendation based on category\n",
    "        if category == \"black_listed\":\n",
    "            recommendation = \"Blacklist / Do not prioritize. Optionally attempt one polite re-connect later (low priority).\"\n",
    "        elif category == \"good_call\":\n",
    "            recommendation = \"Follow up: schedule another call or send requested info. Medium priority.\"\n",
    "        else:  # highly_important\n",
    "            recommendation = \"Immediate follow-up: assign high priority sales outreach; send proposal/arrange meeting.\"\n",
    "\n",
    "        result = {\n",
    "            \"category\": category,\n",
    "            \"score\": round(score, 2),\n",
    "            \"signals\": dict(signals),\n",
    "            \"reason\": reason,\n",
    "            \"recommendation\": recommendation,\n",
    "            \"evidence_snippets\": evidence[:10]  # up to 10 supporting snippets\n",
    "        }\n",
    "        return result\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "categorizer = ConversationCategorizer(conversation)\n",
    "report = categorizer.categorize()\n",
    "\n",
    "print(\"=== Conversation Categorization ===\")\n",
    "print(\"Category:\", report[\"category\"])\n",
    "print(\"Score:\", report[\"score\"])\n",
    "print(\"Recommendation:\", report[\"recommendation\"])\n",
    "print(\"Signals:\", report[\"signals\"])\n",
    "print(\"Reason:\", report[\"reason\"])\n",
    "print(\"\\nEvidence snippets (sample):\")\n",
    "for tag, snippet in report[\"evidence_snippets\"]:\n",
    "    print(f\"- [{tag}] {snippet}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3735ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Summary ===\n",
      "Category: highly_important\n",
      "Buyer wants: looking for an apartment or property\n",
      "Follow-up conversation happened?: No\n"
     ]
    }
   ],
   "source": [
    "# ---- Final summary: Buyer Intent + Follow-up detection ----\n",
    "import re\n",
    "\n",
    "class BuyerIntentFollowupSummary:\n",
    "    \"\"\"\n",
    "    Produces a clean final summary:\n",
    "      - 'buyer_wants': what the buyer is looking for (intent)\n",
    "      - 'follow_up_happened': True/False\n",
    "    Works for good_call or highly_important conversations.\n",
    "    \"\"\"\n",
    "\n",
    "    INTEREST_PATTERNS = {\n",
    "        \"apartment\": [\"apartment\", \"flat\", \"property\", \"house\", \"villa\", \"room\", \"accommodation\"],\n",
    "        \"pricing\": [\"price\", \"pricing\", \"cost\", \"rate\", \"quote\", \"budget\"],\n",
    "        \"demo\": [\"demo\", \"show\", \"visit\", \"inspection\", \"schedule\", \"book a visit\"],\n",
    "        \"purchase\": [\"buy\", \"purchase\", \"order\", \"booking\"],\n",
    "        \"subscription\": [\"subscribe\", \"plan\", \"membership\", \"package\"],\n",
    "        \"followup\": [\"details\", \"information\", \"proposal\", \"brochure\", \"more info\", \"send info\"],\n",
    "        \"job\": [\"job\", \"hiring\", \"position\", \"role\", \"career\"],\n",
    "        \"service\": [\"service\", \"support\", \"maintenance\", \"repair\", \"installation\"]\n",
    "    }\n",
    "\n",
    "    FOLLOWUP_CUES = [\n",
    "        \"call back\", \"call me\", \"send\", \"share\", \"email\", \"arrange\", \"schedule\",\n",
    "        \"book\", \"meeting\", \"demo\", \"visit\", \"proposal\", \"quote\", \"any update\", \"follow up\", \"follow-up\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, conversation_text: str, category: str):\n",
    "        self.raw = conversation_text\n",
    "        self.category = category.lower().strip() if category else \"unknown\"\n",
    "        self.messages = self._split(conversation_text)\n",
    "\n",
    "    def _split(self, text):\n",
    "        lines = text.split(\"\\n\")\n",
    "        msgs, current, buf = [], None, []\n",
    "        for ln in lines:\n",
    "            ln = ln.strip()\n",
    "            if ln.startswith(\"Buyer:\"):\n",
    "                if current:\n",
    "                    msgs.append((current, \" \".join(buf).strip()))\n",
    "                current = \"Buyer\"\n",
    "                buf = [ln.split(\"Buyer:\", 1)[1].strip()]\n",
    "            elif ln.startswith(\"Seller:\"):\n",
    "                if current:\n",
    "                    msgs.append((current, \" \".join(buf).strip()))\n",
    "                current = \"Seller\"\n",
    "                buf = [ln.split(\"Seller:\", 1)[1].strip()]\n",
    "            else:\n",
    "                buf.append(ln)\n",
    "        if current:\n",
    "            msgs.append((current, \" \".join(buf).strip()))\n",
    "        return msgs\n",
    "\n",
    "    def detect_intent(self):\n",
    "        \"\"\"Infer what the buyer wants based on keywords in Buyer messages.\"\"\"\n",
    "        text = \" \".join([t for s, t in self.messages if s == \"Buyer\"]).lower()\n",
    "        intents = []\n",
    "        for key, keywords in self.INTEREST_PATTERNS.items():\n",
    "            if any(k in text for k in keywords):\n",
    "                intents.append(key)\n",
    "        if not intents:\n",
    "            # fallback if no clear intent words, return a default guess\n",
    "            return \"general inquiry\"\n",
    "        # prioritize key domain intents if multiple matched\n",
    "        if \"apartment\" in intents:\n",
    "            return \"looking for an apartment or property\"\n",
    "        if \"purchase\" in intents:\n",
    "            return \"interested in purchasing\"\n",
    "        if \"demo\" in intents:\n",
    "            return \"interested in scheduling a visit or demo\"\n",
    "        if \"pricing\" in intents:\n",
    "            return \"inquiring about pricing or quotation\"\n",
    "        if \"subscription\" in intents:\n",
    "            return \"interested in a subscription plan\"\n",
    "        if \"job\" in intents:\n",
    "            return \"inquiring about a job or position\"\n",
    "        if \"service\" in intents:\n",
    "            return \"interested in services or maintenance\"\n",
    "        return \"general inquiry\"\n",
    "\n",
    "    def detect_followup(self):\n",
    "        \"\"\"Check if any follow-up conversation occurred after buyer interest.\"\"\"\n",
    "        followup_detected = False\n",
    "        for spk, msg in self.messages:\n",
    "            low = msg.lower()\n",
    "            if spk == \"Seller\" and any(k in low for k in self.FOLLOWUP_CUES):\n",
    "                followup_detected = True\n",
    "                break\n",
    "            if spk == \"Buyer\" and any(k in low for k in [\"any update\", \"follow up\", \"follow-up\", \"did you\", \"when\"]):\n",
    "                followup_detected = True\n",
    "                break\n",
    "        return followup_detected\n",
    "\n",
    "    def summarize(self):\n",
    "        if self.category not in {\"good_call\", \"highly_important\"}:\n",
    "            return {\n",
    "                \"category\": self.category,\n",
    "                \"buyer_wants\": \"Not applicable (buyer not interested)\",\n",
    "                \"follow_up_happened\": False\n",
    "            }\n",
    "\n",
    "        intent = self.detect_intent()\n",
    "        followup = self.detect_followup()\n",
    "\n",
    "        return {\n",
    "            \"category\": self.category,\n",
    "            \"buyer_wants\": intent,\n",
    "            \"follow_up_happened\": followup\n",
    "        }\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "# Assume you already have `conv_category` from ConversationCategorizer\n",
    "conv_category = \"highly_important\"  # example\n",
    "summary = BuyerIntentFollowupSummary(conversation, conv_category)\n",
    "result = summary.summarize()\n",
    "\n",
    "print(\"=== Final Summary ===\")\n",
    "print(\"Category:\", result[\"category\"])\n",
    "print(\"Buyer wants:\", result[\"buyer_wants\"])\n",
    "print(\"Follow-up conversation happened?:\", \"Yes\" if result[\"follow_up_happened\"] else \"No\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
